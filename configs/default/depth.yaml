pretrained_model_path: "./stable-diffusion-v1-5"
output_dir: ""    # "./outputs/v1/depth/back"
pretrained_controlnet_path: "./sd-controlnet-depth"

control_config:
  type: "depth"
  control_scale: 1.0

train_data:
  video_path: ""    # "my_video/depth/back/cropspatial"
  prompt: "beautiful scenery"
  n_sample_frames: 8
  width: 512
  height: 512
  sample_start_idx: 0
  sample_frame_rate: 1

validation_data:
  prompts:
    - ""
  video_length: 8
  width: 512
  height: 512
  guidance_scale: 12
  num_steps: 50
  start: "inversion"
  edit_type: "DDIM"


learning_rate: 3e-5
train_batch_size: 1
max_train_steps: 500
validation_steps: 100
trainable_modules:
  - "attn1.to_out"
  - "attn_temp"
  - "norm_temp"
  - "conv_temp"

seed: 0
mixed_precision: fp16
gradient_checkpointing: True
enable_xformers_memory_efficient_attention: True